{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the data set\n",
    "\n",
    "In this notebook, we generate the data set that contains abstracts from six influential Springer journals in philosophy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import unidecode\n",
    "import collections\n",
    "\n",
    "from crossref.restful import Journals, Works\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping DOIs using CrossRef API\n",
    "\n",
    "DOIs are unique identifiers of journal papers. We first use the CrossRef API to scrape the DOIs, title, author name, and publication year of the relevant journal articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthese e-ISSN\n",
    "synthese_issn = \"1573-0964\"\n",
    "# Philosophical studies e-ISSN\n",
    "ps_issn = \"1573-0883\"\n",
    "# Philosophy and Technology e-ISSN\n",
    "pt_issn = \"2210-5441\"\n",
    "# Erkenntnis e-ISSN\n",
    "erk_issn = \"1572-8420\"\n",
    "# JPL e-ISSN\n",
    "jpl_issn = \"1573-0433\"\n",
    "# Minds and Machines\n",
    "mm_issn = \"1572-8641\"\n",
    "\n",
    "# Put into list\n",
    "issns = [synthese_issn, ps_issn, pt_issn, erk_issn, jpl_issn, mm_issn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry 0: A hundred years later: The rise and fall of Frege's influence in language theory\n",
      "Entry 1: Defending virtue epistemology: epistemic dependence in testimony and extended cognition\n",
      "Entry 2: A notorious affair called exportation\n",
      "Entry 3: A Theory of Belief for Scientific Refutations\n",
      "Entry 4: Marcus, Kripke, and the origin of the new theory of reference\n",
      "Entry 5: Het Wonder\n"
     ]
    }
   ],
   "source": [
    "# Initialize Journals and Works object for crossref API calls\n",
    "journals = Journals()\n",
    "works = Works()\n",
    "\n",
    "# Initialize empty list for entries\n",
    "entries = []\n",
    "\n",
    "# Get all DOIs and further metadata from each journal\n",
    "for issn in issns:\n",
    "    # Iterate through journal specific publications\n",
    "    for i, article in enumerate(journals.works(issn)):\n",
    "        try:\n",
    "            # Extract metadata\n",
    "            title = unidecode.unidecode(article[\"title\"][0])\n",
    "            given_name = unidecode.unidecode(article[\"author\"][0].get(\"given\"))\n",
    "            family_name = unidecode.unidecode(article[\"author\"][0].get(\"family\"))\n",
    "            doi = article[\"DOI\"]\n",
    "            type_ = article[\"type\"]\n",
    "            year = article[\"published-print\"].get(\"date-parts\")[0][0]\n",
    "            journal = journals.journal(issn).get(\"title\")\n",
    "        \n",
    "            # Create list with all the entry elements\n",
    "            entry = [title, given_name, family_name, doi, type_, year, journal]\n",
    "            entries.append(entry)\n",
    "            print(f\"Entry {i}: {title}\")\n",
    "        except:\n",
    "            print(f\"Could not extract\")\n",
    "    \n",
    "# Turn into dataframe\n",
    "df = pd.DataFrame(entries, columns=[\"Title\",\"First name\",\"Last name\",\"DOI\",\"Type\",\"Year\",\"Journal\"])\n",
    "\n",
    "# Save to CSV\n",
    "#df.to_csv(\"data/crossref_dois.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthese: 7210\n",
      "Philosophical Studies: 5045\n",
      "Philosophy & Technology: 480\n",
      "Erkenntnis: 2315\n",
      "Journal of Philosophical Logic: 1413\n",
      "Minds and Machines: 705\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/crossref_dois.csv\")\n",
    "\n",
    "# Check distribution over different journals\n",
    "journal_names = df[\"Journal\"].unique()\n",
    "for journal in journal_names:\n",
    "    print(f\"{journal}: {len(df[df['Journal']==journal])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by how often a given article appears\n",
    "df_title_counts = df.groupby(\"Title\").count().sort_values(\"Year\",ascending=False)\n",
    "# Store those titles that appear more than three times\n",
    "duplicate_titles = df_title_counts[df_title_counts[\"DOI\"]>3].index\n",
    "# Remove any entry with such a title from the data frame\n",
    "for duplicate_title in duplicate_titles:\n",
    "    df = df[-(df[\"Title\"]==duplicate_title)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Abstracts using the Springer API\n",
    "\n",
    "In the next step, we will try to retrieve the abstract for each DOI using the Springer API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://api.springernature.com/metadata/json/doi/10.1007/bf00873280?api_key=2353c0417a34ed77a423e7c13c0af0d1\n",
      "#1: A hundred years later: The rise and fall of Frege's influence in language theory\n"
     ]
    }
   ],
   "source": [
    "# Initialize authorization for Springer API\n",
    "springer_api_key = \"2353c0417a34ed77a423e7c13c0af0d1\"\n",
    "base_url = \"http://api.springernature.com/metadata/json/doi/\"\n",
    "\n",
    "# Initialize abstracts list\n",
    "abstracts = []\n",
    "\n",
    "# Loop through DOIs (later change from df_lim to full df)\n",
    "for i, doi in enumerate(df[\"DOI\"]):\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        #API call get content as JSON\n",
    "        url = base_url+doi+\"?api_key=\"+springer_api_key\n",
    "        print(url)\n",
    "        r = requests.get(url)\n",
    "        content = r.json()\n",
    "        \n",
    "        # Check that we're only considering English language abstracts\n",
    "        language = content.get(\"records\")[0].get(\"language\")\n",
    "        if language!=\"en\":\n",
    "            continue\n",
    "        \n",
    "        # Retrieve abstract (and title for verification)\n",
    "        abstract = content.get(\"records\")[0].get(\"abstract\")\n",
    "        title = content.get(\"records\")[0].get(\"title\")\n",
    "        print(f\"#{i+1}: {title}\")\n",
    "    except:\n",
    "        print(\"API call failed\")\n",
    "        entry = [\"Error\",\"Error\",\"Error\"]\n",
    "    else:\n",
    "        entry = [title, abstract, doi]\n",
    "    \n",
    "    abstracts.append(entry)\n",
    "\n",
    "# Turn into data frame and save as CSV\n",
    "abstracts_df = pd.DataFrame(abstracts,columns=[\"Title\",\"Abstract\",\"DOI\"])\n",
    "#abstracts_df.to_csv(\"data/abstracts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the final data set\n",
    "\n",
    "In this final step we merge the data set containing the CrossRef metadata about the publications with the abstracts retrieved using the Springer API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with initial DF\n",
    "df_merged = pd.merge(df,\n",
    "                   abstracts_df,\n",
    "                   on=\"DOI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column which contains the title  and abstract\n",
    "df_merged[\"Text\"] = df_merged[\"Title_x\"]+\" \"+df_merged[\"Abstract\"]\n",
    "# Drop empty column\n",
    "df_merged = df_merged.drop(columns=[\"Unnamed: 0_x\", \"Unnamed: 0_y\"])\n",
    "# Delete entries without abstract\n",
    "df_merged = df_merged[df_merged[\"Abstract\"].str.len()!=0]\n",
    "df_merged = df_merged.dropna(subset=[\"Abstract\"])\n",
    "# Drop duplicates\n",
    "df_merged = df_merged.drop_duplicates()\n",
    "# Drop corrections\n",
    "df_merged = df_merged[-df_merged[\"Title_y\"].str.startswith(\"Correction to:\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthese: 3534\n",
      "Philosophical Studies: 2565\n",
      "Philosophy & Technology: 398\n",
      "Erkenntnis: 1370\n",
      "Journal of Philosophical Logic: 915\n",
      "Minds and Machines: 525\n"
     ]
    }
   ],
   "source": [
    "# Check distribution over different journals\n",
    "journal_names = df_merged[\"Journal\"].unique()\n",
    "\n",
    "for journal in journal_names:\n",
    "    print(f\"{journal}: {len(df_merged[df_merged['Journal']==journal])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved csv file with 9307 abstracts.\n"
     ]
    }
   ],
   "source": [
    "# Save final data frame to csv\n",
    "#df_merged.to_csv(\"data/complete_abstract_data.csv\")\n",
    "print(f\"Saved csv file with {len(df_merged)} abstracts.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
